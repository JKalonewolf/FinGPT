# ğŸ§  FinGPT - AI-Powered Financial Assistant

FinGPT is an open-source financial assistant powered by a local Large Language Model (LLM). It helps users analyze market trends, generate financial reports, answer finance-related questions, and more â€” all privately and offline.

> âš ï¸ **Model Note:** This project uses the `llama-2-7b-chat.gguf` model, which will be automatically downloaded from the authorâ€™s Google Drive during first run.

---

## ğŸ§  Model Setup (Auto-Downloaded)

### âœ… First-Time Use:

When you run the project for the first time, it will automatically:

1. Download the required LLM model from the developer's **Google Drive**.
2. Create a folder named `FinGPT/` in your local environment.
3. Inside `FinGPT/`, you'll find:
    ```
    FinGPT/
    â”œâ”€â”€ data/
    â””â”€â”€ models/
            â””â”€â”€ llama-2-7b-chat.gguf
    ```

4. Go to:
5. Ensure that the file `llama-2-7b-chat.gguf` is present in that folder.

> âœ… **This version (`llama-2-7b-chat.gguf`) is required** for correct operation of the FinGPT system.

If the model file is missing or corrupted, please manually download and place it in that directory.

---

## ğŸ“ Project Structure

```bash
FinGPT/
â”œâ”€â”€ backend/                # (if exists) Flask/FastAPI backend
â”œâ”€â”€ data/                   # Stores processed data
â”œâ”€â”€ ingestion/              # PDF/document ingestion logic
â”œâ”€â”€ models/                 # Holds downloaded model files
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ llama-2-7b-chat.gguf
â”œâ”€â”€ PythonProject/          # (if used as submodule or template)
â”œâ”€â”€ streamlit/              # Streamlit frontend UI
â”œâ”€â”€ uploaded_pdfs/          # Uploaded PDFs for analysis
â”œâ”€â”€ utils/                  # Utility scripts
â”œâ”€â”€ .env                    # Environment variables
â”œâ”€â”€ app.py                  # Main Streamlit app entry
â”œâ”€â”€ api_handler.py          # Handles model and app API logic
â”œâ”€â”€ download_models.py      # Downloads llama model automatically
â”œâ”€â”€ faiss_indexer.py        # Vector store indexing
â”œâ”€â”€ huggingface_api.py      # (if used) HuggingFace fallback support
â”œâ”€â”€ local_llama.py          # Loads and runs local llama model
â”œâ”€â”€ pdf_extractor.py        # PDF parsing logic
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md               # You're here!
## ğŸ› ï¸ Quick Start

```bash
git clone https://github.com/JKalonewolf/FinGPT.git
cd FinGPT

python -m venv venv
venv\Scripts\activate      # On Windows
source venv/bin/activate   # On macOS/Linux

pip install -r requirements.txt


Run the App
Make sure your virtual environment is active.
bash
python app.py


---

âœ… Let me know when you're ready to insert this into your `README.md` file directly, or if you'd like a downloadable version.

Also, **share the Google Drive model link**, so I can update the `[Google Drive Link Here]` with the actual clickable download.

